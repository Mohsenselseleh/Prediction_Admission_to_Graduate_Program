{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.discrete.discrete_model as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are interested to see how variables, such as GRE (Graduate Record Exam scores), GPA (grade point average) and prestige of the undergraduate institution, effect admission into graduate school at UCLA. The data for this analysis is collected from (http://stats.idre.ucla.edu/).\n",
    "#The admit variable, admit/not admitted, is a binary variable. data can be obtained from our website from within R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      admit  gre   gpa  rank\n",
       "0        0  380  3.61     3\n",
       "1        1  660  3.67     3\n",
       "2        1  800  4.00     1\n",
       "3        1  640  3.19     4\n",
       "4        0  520  2.93     4\n",
       "..     ...  ...   ...   ...\n",
       "395      0  620  4.00     2\n",
       "396      0  560  3.04     3\n",
       "397      0  460  2.63     2\n",
       "398      0  700  3.65     2\n",
       "399      0  600  3.89     3\n",
       "\n",
       "[400 rows x 4 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")\n",
    "## view the first few rows of the data\n",
    "mydata.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset has a binary response (outcome, dependent) variable called admit.\n",
    "#There are three predictor variables: gre, gpa and rank. We will treat the variables gre and gpa as continuous.\n",
    "#The variable rank takes on the values 1 through 4. Institutions with a rank of 1 have the highest prestige, while those with a rank of 4 have the lowest. We can get basic descriptives for the entire data set by using summary. To get the standard deviations,\n",
    "#we use sapply to apply the sd function to each variable in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>587.700000</td>\n",
       "      <td>3.389900</td>\n",
       "      <td>2.48500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.516536</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.94446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.395000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa       rank\n",
       "count  400.000000  400.000000  400.000000  400.00000\n",
       "mean     0.317500  587.700000    3.389900    2.48500\n",
       "std      0.466087  115.516536    0.380567    0.94446\n",
       "min      0.000000  220.000000    2.260000    1.00000\n",
       "25%      0.000000  520.000000    3.130000    2.00000\n",
       "50%      0.000000  580.000000    3.395000    2.00000\n",
       "75%      1.000000  660.000000    3.670000    3.00000\n",
       "max      1.000000  800.000000    4.000000    4.00000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code below estimates a logistic regression model using the glm (generalized linear model) function. \n",
    "#First, we convert rank to a factor to indicate that rank should be treated as a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>460</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre   gpa rank_cat\n",
       "0    380  3.61        3\n",
       "1    660  3.67        3\n",
       "2    800  4.00        1\n",
       "3    640  3.19        4\n",
       "4    520  2.93        4\n",
       "..   ...   ...      ...\n",
       "395  620  4.00        2\n",
       "396  560  3.04        3\n",
       "397  460  2.63        2\n",
       "398  700  3.65        2\n",
       "399  600  3.89        3\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata['rank_cat'] = mydata['rank'].astype('category')\n",
    "feature_cols = ['gre', 'gpa', 'rank_cat']\n",
    "X = mydata[feature_cols] # independent variable\n",
    "Y = mydata.admit # dependent variable\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices('admit ~ gre + gpa + C(rank)', mydata, return_type = 'dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573147\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>admit</td>      <th>  No. Observations:  </th>  <td>   400</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   394</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 09 Jun 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.08292</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:32:39</td>     <th>  Log-Likelihood:    </th> <td> -229.26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -249.99</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>7.578e-08</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   -3.9900</td> <td>    1.140</td> <td>   -3.500</td> <td> 0.000</td> <td>   -6.224</td> <td>   -1.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(rank)[T.2]</th> <td>   -0.6754</td> <td>    0.316</td> <td>   -2.134</td> <td> 0.033</td> <td>   -1.296</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(rank)[T.3]</th> <td>   -1.3402</td> <td>    0.345</td> <td>   -3.881</td> <td> 0.000</td> <td>   -2.017</td> <td>   -0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(rank)[T.4]</th> <td>   -1.5515</td> <td>    0.418</td> <td>   -3.713</td> <td> 0.000</td> <td>   -2.370</td> <td>   -0.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>          <td>    0.0023</td> <td>    0.001</td> <td>    2.070</td> <td> 0.038</td> <td>    0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>          <td>    0.8040</td> <td>    0.332</td> <td>    2.423</td> <td> 0.015</td> <td>    0.154</td> <td>    1.454</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  400\n",
       "Model:                          Logit   Df Residuals:                      394\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Wed, 09 Jun 2021   Pseudo R-squ.:                 0.08292\n",
       "Time:                        09:32:39   Log-Likelihood:                -229.26\n",
       "converged:                       True   LL-Null:                       -249.99\n",
       "Covariance Type:            nonrobust   LLR p-value:                 7.578e-08\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       -3.9900      1.140     -3.500      0.000      -6.224      -1.756\n",
       "C(rank)[T.2]    -0.6754      0.316     -2.134      0.033      -1.296      -0.055\n",
       "C(rank)[T.3]    -1.3402      0.345     -3.881      0.000      -2.017      -0.663\n",
       "C(rank)[T.4]    -1.5515      0.418     -3.713      0.000      -2.370      -0.733\n",
       "gre              0.0023      0.001      2.070      0.038       0.000       0.004\n",
       "gpa              0.8040      0.332      2.423      0.015       0.154       1.454\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = sm.Logit(Y, X)\n",
    "logreg = logit.fit()\n",
    "logreg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "***\n",
    "# How do you analyze the outputs of this model?\n",
    "\n",
    "***\n",
    "\n",
    "#* In the output above, the first thing we see is the call, this is R reminding us what the model we ran was,\n",
    "#what options we specified, etc.\n",
    "\n",
    "#* Next we see the deviance residuals, which are a measure of model fit. \n",
    "#This part of output shows the distribution of the deviance residuals for individual cases used in the model.\n",
    "#Below we discuss how to use summaries of the deviance statistic to assess model fit.\n",
    "\n",
    "#* The next part of the output shows the coefficients, their standard errors,\n",
    "#the z-statistic (sometimes called a Wald z-statistic), and the associated p-values.\n",
    "#Both gre and gpa are statistically significant, as are the three terms for rank. \n",
    "#The logistic regression coefficients give the change in the log odds of the outcome for a one unit increase in the predictor variable.\n",
    " #   + For every one unit change in GRE, the log odds of admission (versus non-admission) increases by 0.002.\n",
    "   \n",
    "#    + For a one unit increase in GPA, the log odds of being admitted to graduate school increases by 0.804.\n",
    "    \n",
    " #   + The indicator variables for rank have a slightly different interpretation.\n",
    "#For example, having attended an undergraduate institution with rank of 2, versus an institution with a rank of 1, changes the log odds of admission by -0.675."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**Plotting logistic regression and classes in R**\n",
    "\n",
    "#Create an imaginary dataset of 20 individuals of different body sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "std = 2\n",
    "mean = 30\n",
    "bodysize = np.random.normal(loc=mean, scale=std, size=n)\n",
    "bodysize = np.array([26,27,28,28,28,28,29,29,29,29,30,30,30,30,31,31,32,32,34,35])\n",
    "survive= np.array([0,0,0,0,0,1,0,1,0,0,1,1,0,1,1,1,0,1,1,1])\n",
    "dat = pd.DataFrame({'bodysize':bodysize,'survive':survive})\n",
    "y, X = dmatrices('survive ~ bodysize', dat, return_type = 'dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can plot using the glm model based on each feature as follows. Here we just have one feature which is Body Size:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.507163\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit = sm.Logit(y , X)\n",
    "logreg = logit.fit()\n",
    "pred = logreg.predict(X)\n",
    "plt.scatter(dat['bodysize'], dat['survive'])\n",
    "plt.scatter(dat['bodysize'], pred)\n",
    "plt.xlabel('Bodysize')\n",
    "plt.xlabel('Survive Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3.Read the yelp dataset provided in the course shell. \n",
    "yelp = pd.read_csv('https://raw.githubusercontent.com/DrUzair/MLSD/master/Datasets/yelp_lab8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*Note on the Dataset*: \n",
    "#This dataset has been pre-processed and includes the restaurants registered in Yelp platform within the regions of Toronto, Markham and Mississauga. \n",
    "#The original dataset is downloaded from: https://www.kaggle.com/ivy1219/analysis-on-yelp/data or can be directly downloaded from yelp website in JSON or SQL format: https://www.yelp.com/dataset. \n",
    "#Here is the description given from the Yelp website: \"The Yelp dataset is a subset of our businesses, reviews, and user data for use in personal, educational, and academic purposes. Available in both JSON and SQL files, use it to teach students about databases, to learn NLP, or for sample production data while you learn how to make mobile apps.\"\n",
    "\n",
    "#*Goal*\n",
    "#The goal is to estimate how well will a restaurant's rating be, through the number of stars on Yelp, depending on the type of restaurant, location and number of reviews. We want to know if a restaurant will be rated as 4 or 5 stars or less than 4 stars.\n",
    "#Our dependent variable is: stars.\n",
    "#For simplicity, we have gruped the stars variable as follows: \n",
    "#- 1, 1.5, 2, 2.5, 3 or 3.5 stars are set to 0 (considered a 'failure' in the glm model)\n",
    "#- 4, 4.5, or 5 stars are set to 1 (considered a 'success' in the glm model)\n",
    "\n",
    "#*Splitting the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(yelp, train_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.623758\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>stars</td>      <th>  No. Observations:  </th>  <td>  6453</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  6441</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    11</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 09 Jun 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.02474</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:40:26</td>     <th>  Log-Likelihood:    </th> <td> -4025.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -4127.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>9.756e-38</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                          <td>   -1.5881</td> <td>    0.116</td> <td>  -13.741</td> <td> 0.000</td> <td>   -1.815</td> <td>   -1.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Missisauga]</th>                 <td>    0.6905</td> <td>    0.131</td> <td>    5.259</td> <td> 0.000</td> <td>    0.433</td> <td>    0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Toronto]</th>                    <td>    0.6359</td> <td>    0.114</td> <td>    5.569</td> <td> 0.000</td> <td>    0.412</td> <td>    0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categories[T.Coffee or Sandwiches]</th> <td>    0.6718</td> <td>    0.092</td> <td>    7.325</td> <td> 0.000</td> <td>    0.492</td> <td>    0.852</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categories[T.Fast Food]</th>            <td>   -0.2321</td> <td>    0.092</td> <td>   -2.526</td> <td> 0.012</td> <td>   -0.412</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categories[T.Italian]</th>              <td>    0.5280</td> <td>    0.161</td> <td>    3.281</td> <td> 0.001</td> <td>    0.213</td> <td>    0.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categories[T.Latin]</th>                <td>    0.4463</td> <td>    0.132</td> <td>    3.391</td> <td> 0.001</td> <td>    0.188</td> <td>    0.704</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categories[T.Middle Eastern]</th>       <td>    0.2053</td> <td>    0.094</td> <td>    2.183</td> <td> 0.029</td> <td>    0.021</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categories[T.North American]</th>       <td>    0.2303</td> <td>    0.100</td> <td>    2.304</td> <td> 0.021</td> <td>    0.034</td> <td>    0.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categories[T.Other]</th>                <td>    0.4639</td> <td>    0.104</td> <td>    4.441</td> <td> 0.000</td> <td>    0.259</td> <td>    0.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categories[T.Pub]</th>                  <td>    0.4792</td> <td>    0.110</td> <td>    4.352</td> <td> 0.000</td> <td>    0.263</td> <td>    0.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>review_count</th>                       <td>    0.0024</td> <td>    0.000</td> <td>    5.880</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  stars   No. Observations:                 6453\n",
       "Model:                          Logit   Df Residuals:                     6441\n",
       "Method:                           MLE   Df Model:                           11\n",
       "Date:                Wed, 09 Jun 2021   Pseudo R-squ.:                 0.02474\n",
       "Time:                        09:40:26   Log-Likelihood:                -4025.1\n",
       "converged:                       True   LL-Null:                       -4127.2\n",
       "Covariance Type:            nonrobust   LLR p-value:                 9.756e-38\n",
       "======================================================================================================\n",
       "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "Intercept                             -1.5881      0.116    -13.741      0.000      -1.815      -1.362\n",
       "city[T.Missisauga]                     0.6905      0.131      5.259      0.000       0.433       0.948\n",
       "city[T.Toronto]                        0.6359      0.114      5.569      0.000       0.412       0.860\n",
       "categories[T.Coffee or Sandwiches]     0.6718      0.092      7.325      0.000       0.492       0.852\n",
       "categories[T.Fast Food]               -0.2321      0.092     -2.526      0.012      -0.412      -0.052\n",
       "categories[T.Italian]                  0.5280      0.161      3.281      0.001       0.213       0.843\n",
       "categories[T.Latin]                    0.4463      0.132      3.391      0.001       0.188       0.704\n",
       "categories[T.Middle Eastern]           0.2053      0.094      2.183      0.029       0.021       0.390\n",
       "categories[T.North American]           0.2303      0.100      2.304      0.021       0.034       0.426\n",
       "categories[T.Other]                    0.4639      0.104      4.441      0.000       0.259       0.669\n",
       "categories[T.Pub]                      0.4792      0.110      4.352      0.000       0.263       0.695\n",
       "review_count                           0.0024      0.000      5.880      0.000       0.002       0.003\n",
       "======================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, X_train = dmatrices('stars ~ city + review_count + categories', train_set, return_type = 'dataframe')\n",
    "logit = sm.Logit(y_train , X_train)\n",
    "logreg = logit.fit()\n",
    "logreg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before proceeding to the model evaluation, let us predict an outcome with the glm_model that we constructed on the training set.\n",
    "\n",
    "#Let's assume a new coffee shop has just opened in Toronto and wants to know how many stars it is likely to get if the business registers in Yelp. The coffee shop is expecting to receive 200 reviews from its customers. \n",
    "#Predict the likelihood of the coffee shop to be ranked as 4, 4.5 or 5 stars. Derive the result using the information in summary(glm_model) on one hand, and using the 'predict' function.\n",
    "\n",
    "#Hint for using the information in summary(glm_model): 1/(1+exp(-(y)), where y is the output of the linear model. Remember that glm gives us the log odds of a restaurant (or coffee shop) to have 4, 4.5 or 5 stars.\n",
    "\n",
    "#Manual Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/(1+exp(-((Intercept)+cityToronto+200*review_count+categoriesCoffee or Sandwiches))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1784   23]\n",
      " [ 929   30]]\n",
      "0.6558206796818511\n"
     ]
    }
   ],
   "source": [
    "y_test, X_test = dmatrices('stars ~ city + review_count + categories', test_set, return_type = 'dataframe')\n",
    "pred = logreg.predict(X_test)\n",
    "pred = pred > 0.5\n",
    "actual = y_test > 0.5\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(actual, pred)\n",
    "print(cm)\n",
    "accuracy = float((cm[0][0] + cm[1][1]))/float(len(actual))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this approach, we have set the threshhold to 0.5. \n",
    "#Meaning that all probability equal or higher to 0.5 will be classified as a success (greater than 4 stars ranking)\n",
    "#and all probability less than 0.5 will be classified as a failure (less than 4 stars ranking). \n",
    "#Try to change the threshhold and compare the accuracy level of the classifer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
